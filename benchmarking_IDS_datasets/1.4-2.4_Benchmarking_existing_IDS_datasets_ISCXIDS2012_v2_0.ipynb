{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9GPqNbjo6r2"
      },
      "source": [
        "# Intrusion Detection System (IDS) Public Datasets Benchmarking\n",
        "\n",
        "In cybersecurity, the design, development, and implementation of effective Intrusion Detection Systems (IDS) are important for safeguarding IT&C infrastructures from unauthorized access, data breaches, and various forms of malicious activities. The selection of an appropriate ML/DL algorithm plays a essential role in ensuring the security and integrity of protected systems.\n",
        "\n",
        "But before we can dive in the development of a new-edge algorithm, we shoud have the appropriate data, that needs to be studied and analysed in order to undestant the reality and challenges of our ML problem. In accordance with this paradigm, we chosed to study the early created datasets designed for IDS systems in order to derive leasons learn for feature dataset development.\n",
        "\n",
        "This experiment aims to comprehensively evaluate the performance of different ML and DL algorithms on a variety of datasets, encompassing a wide range of network traffic scenarios. The datasets used for this analysis include well-known benchmark datasets such as KDD, NSL-KDD, CTU-13, ISCXIDS2012, CIC-IDS2017, CSE-CIC-IDS2018, and Kyoto 2006+. Each dataset represents a distinct set of challenges and characteristics, making this evaluation both diverse and insightful.\n",
        "\n",
        "The experiment is divided into three main phases:\n",
        "\n",
        "1. **Data Acquisition and Preprocessing**:\n",
        " - In this phase, we acquire the selected datasets from reputable sources, ensuring the integrity and accuracy of the data.\n",
        " - Data preprocessing tasks include handling missing values, selecting the most relevant features using feature selection techniques, normalizing the data, and, if necessary, performing feature engineering to enhance the dataset's suitability for machine learning.\n",
        "\n",
        "2. **Algorithm Evaluation**:\n",
        " - We evaluate the performance of a range of ML/DL algorithms on each dataset. The chosen algorithms include baseline methods like ZeroRule and OneRule, traditional machine learning approaches like Naive Bayes and Random Forest, as well as some of the most used anomaly detection deep learning algorithms.\n",
        " - Cross-validation is applied to ensure the robustness of our results. Performance metrics such as precision, variance, and Mean Absolute Error (MAE) are calculated for each algorithm and dataset.\n",
        "\n",
        "3. **Results and Insights**:\n",
        " - The results of this evaluation provide valuable insights into the strengths and weaknesses of different IDS algorithms under various conditions.\n",
        " - We analyze the performance of algorithms on both the original datasets and balanced datasets to address the challenge of class imbalance in intrusion detection.\n",
        " - Observations and additional details regarding the algorithms' performance are documented, providing a comprehensive overview of their behavior.\n",
        "\n",
        "By conducting this experiment, we aim to contribute to the understanding of cyber domain dataset generation. The findings will assist in making informed decisions when developing a cybersecurity AI application, by deriving necesary steps and procedures in selecting the appropriate learning data.\n",
        "\n",
        "The following sections of this Jupyter notebook will provide a detailed walkthrough of the experiment, including code snippets, visualizations, and discussions of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KtMV8ZjUwala",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318514ff-828e-46e0-9cd2-4e4eb2d92177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from psutil import virtual_memory\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Function to get CPU information\n",
        "def get_cpu_info():\n",
        "    cpu_info = os.popen('lscpu').read()\n",
        "    return cpu_info\n",
        "\n",
        "# Function to get RAM information\n",
        "def get_ram_info():\n",
        "    ram = virtual_memory()\n",
        "    total_ram = f\"{ram.total / 1e9:.2f} GB\"\n",
        "    available_ram = f\"{ram.available / 1e9:.2f} GB\"\n",
        "    return total_ram, available_ram\n",
        "\n",
        "# Function to get GPU information\n",
        "def get_gpu_info():\n",
        "    # Execute nvidia-smi and get its output\n",
        "    gpu_info = os.popen('nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits').read().strip()\n",
        "\n",
        "    # Split the output to get individual GPU details\n",
        "    details = gpu_info.split(\", \")\n",
        "\n",
        "    # Return GPU name, total, used, and free memory\n",
        "    return details[0], f\"{details[1]} MB\", f\"{details[2]} MB\", f\"{details[3]} MB\"\n",
        "\n",
        "# Collect system information\n",
        "cpu_info = get_cpu_info()\n",
        "total_ram, available_ram = get_ram_info()\n",
        "try:\n",
        "  gpu_name, gpu_total_memory, gpu_used_memory, gpu_free_memory = get_gpu_info()\n",
        "except:\n",
        "  gpu_name, gpu_total_memory, gpu_used_memory, gpu_free_memory = 'null',0,0,0\n",
        "\n",
        "# Extract relevant CPU information\n",
        "cpu_type = \"\"\n",
        "cpu_architecture = \"\"\n",
        "\n",
        "for line in cpu_info.splitlines():\n",
        "    if \"Model name:\" in line:\n",
        "        cpu_type = line.split(\":\")[1].strip()\n",
        "    elif \"Architecture:\" in line:\n",
        "        cpu_architecture = line.split(\":\")[1].strip()\n",
        "\n",
        "# Create a table\n",
        "table = [\n",
        "    [\"CPU Type\", cpu_type],\n",
        "    [\"CPU Architecture\", cpu_architecture],\n",
        "    [\"Total RAM\", total_ram],\n",
        "    [\"Available RAM\", available_ram],\n",
        "    [\"GPU Name\", gpu_name],\n",
        "    [\"GPU Total Memory\", gpu_total_memory],\n",
        "    [\"GPU Used Memory\", gpu_used_memory],\n",
        "    [\"GPU Free Memory\", gpu_free_memory]\n",
        "]\n",
        "\n",
        "# Display the table\n",
        "print(tabulate(table, headers=[\"Characteristic\", \"Value\"], tablefmt=\"pretty\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahPNolp1hx9y",
        "outputId": "8a04f9ab-255c-40aa-f663-90958de6c4de"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------------------+\n",
            "|  Characteristic  |             Value              |\n",
            "+------------------+--------------------------------+\n",
            "|     CPU Type     | Intel(R) Xeon(R) CPU @ 2.20GHz |\n",
            "| CPU Architecture |             x86_64             |\n",
            "|    Total RAM     |            54.76 GB            |\n",
            "|  Available RAM   |            19.26 GB            |\n",
            "|     GPU Name     |              null              |\n",
            "| GPU Total Memory |               0                |\n",
            "| GPU Used Memory  |               0                |\n",
            "| GPU Free Memory  |               0                |\n",
            "+------------------+--------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzsb4uZasyyg"
      },
      "source": [
        "## 1. Data Acquisition and Preprocessing\n",
        "\n",
        "In this section, we focus on acquiring the above mentioned datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-rZmvktk4m"
      },
      "source": [
        "### 1.4. ISCXIDS2012 dataset\n",
        "\n",
        "The ISCXIDS2012 dataset has been meticulously designed to assess the efficacy of intrusion detection systems in identifying and mitigating network-based cyber threats. This dataset is curated from real-world network traffic data recorded in a controlled laboratory setting. Comprising multiple distinct scenarios, ISCXIDS2012 represents various network attacks and intrusion scenarios, providing a comprehensive evaluation platform for cybersecurity research. These scenarios encompass a diverse spectrum of cyber threats, encompassing botnet activities, Distributed Denial of Service (DDoS) attacks, brute-force, and an array of Web attacks, rendering it an invaluable asset for our study."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Unzip ISCXIDS2012 dataset"
      ],
      "metadata": {
        "id": "QIJ4uY7hK9Dk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dZJZ_BPiWFa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903bb887-19a6-4f9e-859c-5e60f537767d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzip complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Define the source URL\n",
        "src_url = \"http://205.174.165.80/CICDataset/ISCX-IDS-2012/Dataset/labeled_flows_xml.zip\"\n",
        "\n",
        "# Define the destination folder\n",
        "destination_folder = \"/content/drive/MyDrive/ISCXIDS2012\"\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Define the destination file path\n",
        "dest_file = os.path.join(destination_folder, \"labeled_flows_xml.zip\")\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(src_url, stream=True)\n",
        "if not os.path.exists(dest_file):\n",
        "  if response.status_code == 200:\n",
        "      with open(dest_file, \"wb\") as f:\n",
        "          for chunk in response.iter_content(chunk_size=8192):\n",
        "              f.write(chunk)\n",
        "\n",
        "      print(\"Download completed.\")\n",
        "  else:\n",
        "      print(\"Failed to download the file.\")\n",
        "\n",
        "# Check if the Dataset was downlaoded\n",
        "if os.path.exists(dest_file) and len(os.listdir(destination_folder))==1:\n",
        "\n",
        "  # Unzip the downloaded dataset\n",
        "  with zipfile.ZipFile(dest_file, \"r\") as zip_ref:\n",
        "      zip_ref.extractall(destination_folder)\n",
        "\n",
        "  print(\"Unzip complete.\")\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Dataset already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8MMlugG0zTNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5282fee3-e568-42a0-8ff3-cf049e921951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.5G\n",
            "-rw------- 1 root root 394M Oct 10 17:36 labeled_flows_xml.zip\n",
            "-rw------- 1 root root 1.9K Oct 10 18:47 readme.txt\n",
            "-rw------- 1 root root 203M Oct 10 18:47 TestbedMonJun14Flows.xml\n",
            "-rw------- 1 root root  22K Oct 10 18:47 TestbedMonJun14Flows.xsd\n",
            "-rw------- 1 root root 139M Oct 10 18:47 TestbedSatJun12Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:47 TestbedSatJun12Flows.xsd\n",
            "-rw------- 1 root root 283M Oct 10 18:47 TestbedSunJun13Flows.xml\n",
            "-rw------- 1 root root  24K Oct 10 18:47 TestbedSunJun13Flows.xsd\n",
            "-rw------- 1 root root 298M Oct 10 18:47 TestbedThuJun17-1Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:47 TestbedThuJun17-1Flows.xsd\n",
            "-rw------- 1 root root 236M Oct 10 18:47 TestbedThuJun17-2Flows.xml\n",
            "-rw------- 1 root root  24K Oct 10 18:47 TestbedThuJun17-2Flows.xsd\n",
            "-rw------- 1 root root 117M Oct 10 18:47 TestbedThuJun17-3Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:47 TestbedThuJun17-3Flows.xsd\n",
            "-rw------- 1 root root 307M Oct 10 18:47 TestbedTueJun15-1Flows.xml\n",
            "-rw------- 1 root root  24K Oct 10 18:47 TestbedTueJun15-1Flows.xsd\n",
            "-rw------- 1 root root 286M Oct 10 18:47 TestbedTueJun15-2Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:47 TestbedTueJun15-2Flows.xsd\n",
            "-rw------- 1 root root 483M Oct 10 18:47 TestbedTueJun15-3Flows.xml\n",
            "-rw------- 1 root root  24K Oct 10 18:47 TestbedTueJun15-3Flows.xsd\n",
            "-rw------- 1 root root 288M Oct 10 18:48 TestbedWedJun16-1Flows.xml\n",
            "-rw------- 1 root root  24K Oct 10 18:48 TestbedWedJun16-1Flows.xsd\n",
            "-rw------- 1 root root 229M Oct 10 18:48 TestbedWedJun16-2Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:48 TestbedWedJun16-2Flows.xsd\n",
            "-rw------- 1 root root 294M Oct 10 18:48 TestbedWedJun16-3Flows.xml\n",
            "-rw------- 1 root root  23K Oct 10 18:48 TestbedWedJun16-3Flows.xsd\n"
          ]
        }
      ],
      "source": [
        "!ls -ahl '/content/drive/MyDrive/ISCXIDS2012'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Function to parse a single flow element\n",
        "def parse_flow(flow):\n",
        "    flow_data = {}\n",
        "    flow_data['appName'] = flow.find('appName').text\n",
        "    flow_data['totalSourceBytes'] = int(flow.find('totalSourceBytes').text)\n",
        "    flow_data['totalDestinationBytes'] = int(flow.find('totalDestinationBytes').text)\n",
        "    flow_data['totalDestinationPackets'] = int(flow.find('totalDestinationPackets').text)\n",
        "    flow_data['totalSourcePackets'] = int(flow.find('totalSourcePackets').text)\n",
        "    flow_data['direction'] = flow.find('direction').text\n",
        "    flow_data['source'] = flow.find('source').text\n",
        "    flow_data['protocolName'] = flow.find('protocolName').text\n",
        "    flow_data['sourcePort'] = int(flow.find('sourcePort').text)\n",
        "    flow_data['destination'] = flow.find('destination').text\n",
        "    flow_data['destinationPort'] = int(flow.find('destinationPort').text)\n",
        "    flow_data['startDateTime'] = flow.find('startDateTime').text\n",
        "    flow_data['stopDateTime'] = flow.find('stopDateTime').text\n",
        "    flow_data['Tag'] = flow.find('Tag').text\n",
        "    return flow_data\n",
        "\n",
        "# Use the current directory as the xml_folder\n",
        "xml_folder = '/content/drive/MyDrive/ISCXIDS2012'\n",
        "\n",
        "# Get a list of all XML files in the folder\n",
        "xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
        "\n",
        "# Iterate through each XML file\n",
        "for xml_file in xml_files:\n",
        "    # Construct the full path to the XML file\n",
        "    xml_file_path = os.path.join(xml_folder, xml_file)\n",
        "\n",
        "    # Change the file extension from .xml to .csv\n",
        "    csv_file_name = os.path.splitext(xml_file)[0] + '.csv'\n",
        "\n",
        "    # Define the CSV file path for output\n",
        "    csv_file_path = os.path.join(xml_folder, csv_file_name)\n",
        "\n",
        "    # Initialize a list to store the extracted information\n",
        "    results = []\n",
        "\n",
        "    try:\n",
        "        # Parse the XML data from the file\n",
        "        tree = ET.parse(xml_file_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Iterate through all elements in the XML\n",
        "        for element in root.iter():\n",
        "            # Check if the element's name starts with \"Testbed\"\n",
        "            if element.tag.startswith(\"Testbed\"):\n",
        "                flow_data = parse_flow(element)\n",
        "                if flow_data:\n",
        "                    results.append(flow_data)\n",
        "\n",
        "        # Write the extracted data to a CSV file\n",
        "        with open(csv_file_path, mode='w', newline='') as csv_file:\n",
        "            fieldnames = [\n",
        "                'appName', 'totalSourceBytes', 'totalDestinationBytes',\n",
        "                'totalDestinationPackets', 'totalSourcePackets', 'direction', 'source',\n",
        "                'protocolName', 'sourcePort', 'destination', 'destinationPort',\n",
        "                'startDateTime', 'stopDateTime', 'Tag'\n",
        "            ]\n",
        "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "\n",
        "            # Write the CSV header\n",
        "            writer.writeheader()\n",
        "\n",
        "            # Write the data for each flow\n",
        "            for flow in results:\n",
        "                try:\n",
        "                    writer.writerow(flow)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error writing a row to '{csv_file_name}': {e}. Skipping this row.\")\n",
        "\n",
        "        print(f\"Data from '{xml_file}' has been exported to '{csv_file_name}'\")\n",
        "\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error parsing '{xml_file}': {e}. Skipping this file.\")\n",
        "        continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgiFmDh7s7Y_",
        "outputId": "55e76c7c-7093-47fd-96f1-f36c2fded851"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from 'TestbedMonJun14Flows.xml' has been exported to 'TestbedMonJun14Flows.csv'\n",
            "Data from 'TestbedSatJun12Flows.xml' has been exported to 'TestbedSatJun12Flows.csv'\n",
            "Data from 'TestbedSunJun13Flows.xml' has been exported to 'TestbedSunJun13Flows.csv'\n",
            "Error parsing 'TestbedThuJun17-1Flows.xml': not well-formed (invalid token): line 3135760, column 209. Skipping this file.\n",
            "Data from 'TestbedThuJun17-2Flows.xml' has been exported to 'TestbedThuJun17-2Flows.csv'\n",
            "Data from 'TestbedThuJun17-3Flows.xml' has been exported to 'TestbedThuJun17-3Flows.csv'\n",
            "Data from 'TestbedTueJun15-1Flows.xml' has been exported to 'TestbedTueJun15-1Flows.csv'\n",
            "Data from 'TestbedTueJun15-2Flows.xml' has been exported to 'TestbedTueJun15-2Flows.csv'\n",
            "Data from 'TestbedTueJun15-3Flows.xml' has been exported to 'TestbedTueJun15-3Flows.csv'\n",
            "Data from 'TestbedWedJun16-1Flows.xml' has been exported to 'TestbedWedJun16-1Flows.csv'\n",
            "Data from 'TestbedWedJun16-2Flows.xml' has been exported to 'TestbedWedJun16-2Flows.csv'\n",
            "Data from 'TestbedWedJun16-3Flows.xml' has been exported to 'TestbedWedJun16-3Flows.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "encoding = 'ISO-8859-1'  # Specify the correct encoding\n",
        "\n",
        "\n",
        "# Get user input with a prompt\n",
        "csv_folder = '/content/drive/MyDrive/ISCXIDS2012'\n",
        "\n",
        "# List to store individual DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Iterate over the CSV files in the folder\n",
        "for filename in os.listdir(csv_folder):\n",
        "    if filename.endswith(\".csv\") and not filename.startswith(\"ISCXIDS2012\"):\n",
        "\n",
        "\t# Read the CSV file with the specified encoding\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(csv_folder, filename), encoding=encoding)\n",
        "        except UnicodeDecodeError:\n",
        "            print(f'Error: Unable to read {file_path} with encoding {encoding}')\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "ISCXIDS2012_df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "CFZYCCYqjkXh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "CWTTwOftQFCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e0a9f3-b6e7-4c64-cf96-d2e6e635d53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1885519 entries, 0 to 1885518\n",
            "Data columns (total 14 columns):\n",
            " #   Column                   Dtype \n",
            "---  ------                   ----- \n",
            " 0   appName                  object\n",
            " 1   totalSourceBytes         int64 \n",
            " 2   totalDestinationBytes    int64 \n",
            " 3   totalDestinationPackets  int64 \n",
            " 4   totalSourcePackets       int64 \n",
            " 5   direction                object\n",
            " 6   source                   object\n",
            " 7   protocolName             object\n",
            " 8   sourcePort               int64 \n",
            " 9   destination              object\n",
            " 10  destinationPort          int64 \n",
            " 11  startDateTime            object\n",
            " 12  stopDateTime             object\n",
            " 13  Tag                      object\n",
            "dtypes: int64(6), object(8)\n",
            "memory usage: 201.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Information about the starting ISCXIDS2012 DataFrame\n",
        "ISCXIDS2012_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "8wX454k6sBI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "48c68dbc-8ec6-4b0b-82c9-05aa95a0874a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       totalSourceBytes  totalDestinationBytes  totalDestinationPackets  \\\n",
              "count      1.885519e+06           1.885519e+06             1.885519e+06   \n",
              "mean       2.565597e+03           3.511633e+04             3.093461e+01   \n",
              "std        7.879153e+05           1.208891e+06             1.010258e+03   \n",
              "min        0.000000e+00           0.000000e+00             0.000000e+00   \n",
              "25%        2.470000e+02           3.600000e+02             2.000000e+00   \n",
              "50%        4.440000e+02           1.179000e+03             5.000000e+00   \n",
              "75%        8.520000e+02           7.530000e+03             1.200000e+01   \n",
              "max        7.632776e+08           1.254005e+09             8.722240e+05   \n",
              "\n",
              "       totalSourcePackets    sourcePort  destinationPort  \n",
              "count        1.885519e+06  1.885519e+06     1.885519e+06  \n",
              "mean         2.013171e+01  1.461091e+04     2.041804e+03  \n",
              "std          6.917955e+02  2.053254e+04     8.981550e+03  \n",
              "min          0.000000e+00  0.000000e+00     0.000000e+00  \n",
              "25%          3.000000e+00  2.326000e+03     8.000000e+01  \n",
              "50%          6.000000e+00  3.784000e+03     8.000000e+01  \n",
              "75%          1.000000e+01  1.823400e+04     8.000000e+01  \n",
              "max          5.147940e+05  6.553500e+04     6.553500e+04  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e6fc8f8-4ec4-4132-9485-ebda7303a222\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>totalSourceBytes</th>\n",
              "      <th>totalDestinationBytes</th>\n",
              "      <th>totalDestinationPackets</th>\n",
              "      <th>totalSourcePackets</th>\n",
              "      <th>sourcePort</th>\n",
              "      <th>destinationPort</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.885519e+06</td>\n",
              "      <td>1.885519e+06</td>\n",
              "      <td>1.885519e+06</td>\n",
              "      <td>1.885519e+06</td>\n",
              "      <td>1.885519e+06</td>\n",
              "      <td>1.885519e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.565597e+03</td>\n",
              "      <td>3.511633e+04</td>\n",
              "      <td>3.093461e+01</td>\n",
              "      <td>2.013171e+01</td>\n",
              "      <td>1.461091e+04</td>\n",
              "      <td>2.041804e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.879153e+05</td>\n",
              "      <td>1.208891e+06</td>\n",
              "      <td>1.010258e+03</td>\n",
              "      <td>6.917955e+02</td>\n",
              "      <td>2.053254e+04</td>\n",
              "      <td>8.981550e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.470000e+02</td>\n",
              "      <td>3.600000e+02</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>2.326000e+03</td>\n",
              "      <td>8.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.440000e+02</td>\n",
              "      <td>1.179000e+03</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>3.784000e+03</td>\n",
              "      <td>8.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.520000e+02</td>\n",
              "      <td>7.530000e+03</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>1.823400e+04</td>\n",
              "      <td>8.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.632776e+08</td>\n",
              "      <td>1.254005e+09</td>\n",
              "      <td>8.722240e+05</td>\n",
              "      <td>5.147940e+05</td>\n",
              "      <td>6.553500e+04</td>\n",
              "      <td>6.553500e+04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e6fc8f8-4ec4-4132-9485-ebda7303a222')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e6fc8f8-4ec4-4132-9485-ebda7303a222 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e6fc8f8-4ec4-4132-9485-ebda7303a222');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40f84d3b-e08e-42c7-aa45-adb0358908a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40f84d3b-e08e-42c7-aa45-adb0358908a9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40f84d3b-e08e-42c7-aa45-adb0358908a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Some basic statistical details like percentile, mean, std, etc. of the starting ISCXIDS2012 DataFrame\n",
        "ISCXIDS2012_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ISCXIDS2012_df.shape, ISCXIDS2012_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqxSP98_I9pl",
        "outputId": "397e4fab-5def-470b-89e4-37a915ab3471"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1885519, 14),\n",
              " Index(['appName', 'totalSourceBytes', 'totalDestinationBytes',\n",
              "        'totalDestinationPackets', 'totalSourcePackets', 'direction', 'source',\n",
              "        'protocolName', 'sourcePort', 'destination', 'destinationPort',\n",
              "        'startDateTime', 'stopDateTime', 'Tag'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing of the ISCXIDS2012 dataset"
      ],
      "metadata": {
        "id": "2ihheceqKT8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DFfhQvIk7jMn"
      },
      "outputs": [],
      "source": [
        "# Check if the Dataset was not preprocess do:\n",
        "  # 1 # Handling Missing Values\n",
        "  # 2 # Encode Categorical Features and Label\n",
        "  # 3 # Normalization (Min-Max Scaling)\n",
        "  # 4 # Removing duplicate records\n",
        "\n",
        "df_final_file_path = os.path.join(destination_folder, \"ISCXIDS2012.csv\")\n",
        "if not os.path.exists(df_final_file_path):\n",
        "\n",
        "  # Step 1: Handling Missing Values\n",
        "\n",
        "  # Check for missing values, NAN\n",
        "  check_nan = ISCXIDS2012_df.isna().sum().sum()\n",
        "\n",
        "  # Check if missing values are represented as empty values (\",,\")\n",
        "  missing_values_as_empty = ISCXIDS2012_df.applymap(lambda x: x == '')\n",
        "\n",
        "  # Count the number of missing values in each column\n",
        "  missing_values_count = missing_values_as_empty.sum()\n",
        "\n",
        "  # Check if all elements in the missing_values_count Series are different from 0\n",
        "  check_null = (missing_values_count != 0).all()\n",
        "\n",
        "  # Replace empty values with NaN\n",
        "  if (check_null):\n",
        "    ISCXIDS2012_df.replace(\"\", np.nan, inplace=True)\n",
        "\n",
        "  # Impute missing values with the most frequent value for categorical columns and mean for numerical columns\n",
        "  if (check_null or check_nan !=0):\n",
        "    imputer = SimpleImputer(strategy='most_frequent', missing_values=pd.NA)\n",
        "    for col in ISCXIDS2012_df.columns:\n",
        "        if ISCXIDS2012_df[col].dtype == 'object':\n",
        "            ISCXIDS2012_df[col] = imputer.fit_transform(df[[col]])\n",
        "        else:\n",
        "            ISCXIDS2012_df[col] = ISCXIDS2012_df[col].fillna(ISCXIDS2012_df[col].mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again for missing values, NAN\n",
        "ISCXIDS2012_df.isna().sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0AJQXkZNPlK",
        "outputId": "054ad9fe-0a1a-40ec-ce8f-badcc8d3bc12"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appName                    0\n",
              "totalSourceBytes           0\n",
              "totalDestinationBytes      0\n",
              "totalDestinationPackets    0\n",
              "totalSourcePackets         0\n",
              "direction                  0\n",
              "source                     0\n",
              "protocolName               0\n",
              "sourcePort                 0\n",
              "destination                0\n",
              "destinationPort            0\n",
              "startDateTime              0\n",
              "stopDateTime               0\n",
              "Tag                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # 2 # Encode Categorical Features and Label\n",
        "\n",
        "df = ISCXIDS2012_df.copy()\n",
        "\n",
        "#['appName','direction','source','protocolName','destination','startDateTime','stopDateTime','Tag']\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "ISCXIDS2012_df['appName'] = ISCXIDS2012_df['appName'].astype('category').cat.codes\n",
        "ISCXIDS2012_df['appName'] = ISCXIDS2012_df['appName'].astype(np.int32)\n",
        "\n",
        "ISCXIDS2012_df['direction'] = ISCXIDS2012_df['direction'].astype('category').cat.codes\n",
        "ISCXIDS2012_df['direction'] = ISCXIDS2012_df['direction'].astype(np.int32)\n",
        "\n",
        "ISCXIDS2012_df['source'] = ISCXIDS2012_df['source'].astype('category').cat.codes\n",
        "ISCXIDS2012_df['source'] = ISCXIDS2012_df['source'].astype(np.int32)\n",
        "\n",
        "ISCXIDS2012_df['destination'] = ISCXIDS2012_df['destination'].astype('category').cat.codes\n",
        "ISCXIDS2012_df['destination'] = ISCXIDS2012_df['destination'].astype(np.int32)\n",
        "\n",
        "ISCXIDS2012_df['protocolName'] = ISCXIDS2012_df['protocolName'].astype('category').cat.codes\n",
        "ISCXIDS2012_df['protocolName'] = ISCXIDS2012_df['protocolName'].astype(np.int32)\n",
        "\n",
        "# Drop startDateTime and stopDateTime\n",
        "ISCXIDS2012_df.drop(['startDateTime', 'stopDateTime'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Jo-kwZVfMuOY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top 10 most frequent values and their counts in the 'Tag' column of CTU-13\n",
        "print(ISCXIDS2012_df.Tag.value_counts().head(10))\n",
        "\n",
        "# Change the data type of the 'Tag' column to 'object' (string)\n",
        "ISCXIDS2012_df['Tag'] = ISCXIDS2012_df['Tag'].astype(dtype='object')\n",
        "\n",
        "# Check if the 'Tag' column starts with the string 'Attack', and assign a Boolean value accordingly\n",
        "ISCXIDS2012_df['Tag'] = ISCXIDS2012_df['Tag'].str.startswith('Attack', na=False)\n",
        "\n",
        "# Change the data type of the 'Tag' column to 'float32'\n",
        "ISCXIDS2012_df['Tag'] = ISCXIDS2012_df['Tag'].astype(dtype='float32', copy=False)\n",
        "\n",
        "# Display again the top 10 most frequent values and their counts in the 'Tag' column of CTU-13 after modifications\n",
        "print(ISCXIDS2012_df.Tag.value_counts().head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwFkk2TtOzwY",
        "outputId": "15253834-53a6-42ff-8d3a-1b6514195177"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal    1816609\n",
            "Attack      68910\n",
            "Name: Tag, dtype: int64\n",
            "0.0    1816609\n",
            "1.0      68910\n",
            "Name: Tag, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if the Dataset was not preprocess do:\n",
        "if not os.path.exists(df_final_file_path):\n",
        "\n",
        "  # Step 3: Normalization (Min-Max Scaling)\n",
        "\n",
        "  #columns = [col for col in ISCXIDS2012_df.columns if col not in ['appName','direction','source','protocolName','destination','startDateTime','stopDateTime','Tag']]\n",
        "  min_max_scaler = MinMaxScaler().fit(ISCXIDS2012_df)\n",
        "  ISCXIDS2012_df = pd.DataFrame(data=min_max_scaler.transform(ISCXIDS2012_df), columns=ISCXIDS2012_df.columns)\n",
        "\n",
        "display(ISCXIDS2012_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "PD_lGwMLn3gH",
        "outputId": "c7b66904-c122-4750-c99b-a54857ff44ff"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    appName  totalSourceBytes  totalDestinationBytes  totalDestinationPackets  \\\n",
              "0  0.830189      2.106180e-05           0.000000e+00                 0.000000   \n",
              "1  0.179245      5.030935e-07           0.000000e+00                 0.000000   \n",
              "2  0.084906      2.240338e-07           5.119595e-07                 0.000005   \n",
              "3  0.179245      5.030935e-07           0.000000e+00                 0.000000   \n",
              "4  0.179245      2.436859e-07           1.020729e-07                 0.000002   \n",
              "\n",
              "   totalSourcePackets  direction    source  protocolName  sourcePort  \\\n",
              "0            0.000346   0.333333  0.269822           1.0    0.081682   \n",
              "1            0.000012   0.333333  0.265372           0.8    0.067674   \n",
              "2            0.000004   0.000000  0.268608           1.0    0.067567   \n",
              "3            0.000012   0.333333  0.268608           0.8    0.055528   \n",
              "4            0.000004   0.333333  0.268608           0.8    0.055558   \n",
              "\n",
              "   destination  destinationPort  Tag  \n",
              "0     0.438092         0.081682  0.0  \n",
              "1     0.313352         0.001221  0.0  \n",
              "2     0.234590         0.000809  0.0  \n",
              "3     0.424007         0.001221  0.0  \n",
              "4     0.980615         0.001221  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fc2bb2e-a416-40f4-8bdd-f8282189b1f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appName</th>\n",
              "      <th>totalSourceBytes</th>\n",
              "      <th>totalDestinationBytes</th>\n",
              "      <th>totalDestinationPackets</th>\n",
              "      <th>totalSourcePackets</th>\n",
              "      <th>direction</th>\n",
              "      <th>source</th>\n",
              "      <th>protocolName</th>\n",
              "      <th>sourcePort</th>\n",
              "      <th>destination</th>\n",
              "      <th>destinationPort</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.830189</td>\n",
              "      <td>2.106180e-05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.269822</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.081682</td>\n",
              "      <td>0.438092</td>\n",
              "      <td>0.081682</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.179245</td>\n",
              "      <td>5.030935e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.265372</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.067674</td>\n",
              "      <td>0.313352</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.084906</td>\n",
              "      <td>2.240338e-07</td>\n",
              "      <td>5.119595e-07</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268608</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.067567</td>\n",
              "      <td>0.234590</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.179245</td>\n",
              "      <td>5.030935e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.268608</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.055528</td>\n",
              "      <td>0.424007</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.179245</td>\n",
              "      <td>2.436859e-07</td>\n",
              "      <td>1.020729e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.268608</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.055558</td>\n",
              "      <td>0.980615</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fc2bb2e-a416-40f4-8bdd-f8282189b1f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fc2bb2e-a416-40f4-8bdd-f8282189b1f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fc2bb2e-a416-40f4-8bdd-f8282189b1f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8758d80f-6dfb-4b6f-bb0c-4386270e0d23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8758d80f-6dfb-4b6f-bb0c-4386270e0d23')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8758d80f-6dfb-4b6f-bb0c-4386270e0d23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # 4 # Removing duplicate records\n",
        "\n",
        "# Print the shape of the DataFrame 'ISCXIDS2012_df' after removing rows with missing values\n",
        "print(ISCXIDS2012_df.shape)\n",
        "\n",
        "# Remove duplicate rows from the DataFrame 'ISCXIDS2012_df' while resetting the index\n",
        "ISCXIDS2012_df = ISCXIDS2012_df.drop_duplicates()\n",
        "ISCXIDS2012_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Print the shape of the DataFrame 'ISCXIDS2012_df' after removing duplicates and resetting the index\n",
        "print(ISCXIDS2012_df.shape)\n",
        "\n",
        "\n",
        "# Print the shape of the DataFrame 'df' after removing rows with missing values\n",
        "print(df.shape)\n",
        "\n",
        "# Remove duplicate rows from the DataFrame 'df' while resetting the index\n",
        "df = df.drop_duplicates()\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Print the shape of the DataFrame 'df' after removing duplicates and resetting the index\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs1UOtdmOop3",
        "outputId": "331d7b70-8b2a-4156-d500-00cd3cca8942"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1885519, 12)\n",
            "(1622767, 12)\n",
            "(1885519, 14)\n",
            "(1746630, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the DataFrames loaded in the memory\n",
        "%whos DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-gl7hTNalVk",
        "outputId": "e18ec336-5f09-4ab5-e43a-eefa6334b13a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                  Type         Data/Info\n",
            "------------------------------------------------\n",
            "ISCXIDS2012_df            DataFrame              appName  totalS<...>622767 rows x 12 columns]\n",
            "X                         DataFrame              appName  totalS<...>622752 rows x 11 columns]\n",
            "df                        DataFrame                       appNam<...>746630 rows x 14 columns]\n",
            "missing_values_as_empty   DataFrame             appName  totalSo<...>885519 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del missing_values_as_empty"
      ],
      "metadata": {
        "id": "MoLmM4s-yIqr"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the resulting dataframes\n",
        "\n",
        "df_file_path = '/content/drive/MyDrive/ISCXIDS2012/ISCXIDS2012.csv'\n",
        "df_encoded_file_path = '/content/drive/MyDrive/ISCXIDS2012/ISCXIDS2012_encoded.csv'\n",
        "\n",
        "# Check if the Dataset is saved:\n",
        "if not os.path.exists(df_file_path):\n",
        "  # Convert your Pandas DataFrame to a CSV file\n",
        "  df.to_csv(df_file_path, index=False)\n",
        "\n",
        "if not os.path.exists(df_encoded_file_path):\n",
        "  # Convert your Pandas DataFrame to a CSV file\n",
        "  ISCXIDS2012_df.to_csv(df_encoded_file_path, index=False)"
      ],
      "metadata": {
        "id": "FiaCpDy9gtdc"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Algorithm Evaluation\n",
        "\n",
        "In this section, we assess the performance of various machine learning algorithms on the upper mentioned datasets."
      ],
      "metadata": {
        "id": "RGr89__ALu4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. ISCXIDS2012 dataset evaluation with baseline and traditional ML algorithms\n",
        "\n",
        "In this section, we evaluate the performance of various machine learning algorithms on the ISCXIDS2012 dataset. We assess the precision and F1 scores, essential indicators of classification accuracy, for a range of algorithms, including fundamental classifiers like Zero Rule and One Rule, statistical approaches like Naive Bayes, and more advanced models such as Random Forest.\n",
        "\n",
        "Given that the ISCXIDS2012 dataset have a limited number of features, to ensure a robust assessment, we employ a 10-fold cross-validation methodology, testing the algorithms on all the features from the dataset. These results offer valuable insights into the optimal dataset generation strategy, aiding in the selection of the most effective feature extraction methods for cybersecurity specific dataset."
      ],
      "metadata": {
        "id": "lClNdKunMbaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip selection of best features due to low count of attributes\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = ISCXIDS2012_df.drop('Tag', axis=1)  # Exclude the label column\n",
        "y = ISCXIDS2012_df['Tag']"
      ],
      "metadata": {
        "id": "7DpcMKATGQhV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.metrics import precision_score, mean_absolute_error, f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the number of desired folds for Cross-Validation (e.g., 10)\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize performance metrics lists\n",
        "results = []\n",
        "\n",
        "# Suppress all warning messages\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "MPMCiS92fwaH"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a file name for saving the results\n",
        "results_file_name = os.path.join(destination_folder, \"iscxids2012_results.pkl\")\n",
        "\n",
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define ZeroRule classifier\n",
        "  zero_rule = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "  # Evaluate ZeroRule classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores = cross_val_score(zero_rule, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores = cross_val_score(zero_rule, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance = np.var(precision_scores)\n",
        "\n",
        "  predictions = cross_val_predict(zero_rule, X, y, cv=num_folds)\n",
        "  mae = mean_absolute_error(y, predictions)\n",
        "\n",
        "  # Display ZeroRule results\n",
        "  print(\"ZeroRule Precision :\", np.mean(precision_scores))\n",
        "  print(\"ZeroRule F1 Score :\", np.mean(f1_scores))\n",
        "  print(\"ZeroRule Variance :\", variance)\n",
        "  print(\"ZeroRule MAE :\", mae)\n",
        "  print(\"ZeroRule Execution Time:\", elapsed_time)\n",
        "\n",
        "  results.append([\"ZeroRule\", np.mean(precision_scores), np.mean(f1_scores), variance, mae, elapsed_time])"
      ],
      "metadata": {
        "id": "X6evNOm1gG1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ee7805-6a4a-485a-db71-e77d0dea0ac9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZeroRule Precision : 0.0\n",
            "ZeroRule F1 Score : 0.0\n",
            "ZeroRule Variance : 0.0\n",
            "ZeroRule MAE : 0.03279891691167001\n",
            "ZeroRule Execution Time: 5.6921117305755615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define OneRule classifier\n",
        "  one_rule = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "  # Evaluate OneRule classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores = cross_val_score(one_rule, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores = cross_val_score(one_rule, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance = np.var(precision_scores)\n",
        "\n",
        "  predictions = cross_val_predict(one_rule, X, y, cv=num_folds)\n",
        "  mae = mean_absolute_error(y, predictions)\n",
        "\n",
        "  # Display OneRule results\n",
        "  print(\"OneRule Precision :\", np.mean(precision_scores))\n",
        "  print(\"OneRule F1 Score :\", np.mean(f1_scores))\n",
        "  print(\"OneRule Variance :\", variance)\n",
        "  print(\"OneRule MAE :\", mae)\n",
        "  print(\"OneRule Execution Time:\", elapsed_time)\n",
        "\n",
        "  results.append([\"OneRule\", np.mean(precision_scores), np.mean(f1_scores), variance, mae, elapsed_time])"
      ],
      "metadata": {
        "id": "36wkD9GMgyzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db502081-9405-4657-86a6-402a89957a4a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneRule Precision : 0.0333212537210722\n",
            "OneRule F1 Score : 0.03162443842440634\n",
            "OneRule Variance : 4.3234639380297525e-06\n",
            "OneRule MAE : 0.06329867442460932\n",
            "OneRule Execution Time: 5.965609788894653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define Naive Bayes classifier\n",
        "  naive_bayes = GaussianNB()\n",
        "\n",
        "  # Evaluate Naive Bayes classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores = cross_val_score(naive_bayes, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores = cross_val_score(naive_bayes, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance = np.var(precision_scores)\n",
        "\n",
        "  predictions = cross_val_predict(naive_bayes, X, y, cv=num_folds)\n",
        "  mae = mean_absolute_error(y, predictions)\n",
        "\n",
        "  # Display Naive Bayes results\n",
        "  print(\"Naive Bayes Precision :\", np.mean(precision_scores))\n",
        "  print(\"Naive Bayes F1 Score :\", np.mean(f1_scores))\n",
        "  print(\"Naive Bayes Variance :\", variance)\n",
        "  print(\"Naive Bayes MAE :\", mae)\n",
        "  print(\"Naive Bayes Execution Time:\", elapsed_time)\n",
        "\n",
        "  results.append([\"Naive Bayes\", np.mean(precision_scores), np.mean(f1_scores), variance, mae, elapsed_time])"
      ],
      "metadata": {
        "id": "8M8M6iicg36h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72be7d59-b6fa-4cf2-8782-903ba7660c82"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Precision : 0.2786100231779066\n",
            "Naive Bayes F1 Score : 0.4317346957207556\n",
            "Naive Bayes Variance : 0.001716265973914469\n",
            "Naive Bayes MAE : 0.08639872514045455\n",
            "Naive Bayes Execution Time: 14.252134561538696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Create a Random Forest classifier with optimized parameters\n",
        "  rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)  # Adjust parameters for optimization\n",
        "\n",
        "  # Evaluate Random Forest classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores = cross_val_score(rf_classifier, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores = cross_val_score(rf_classifier, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance = np.var(precision_scores)\n",
        "\n",
        "  predictions = cross_val_predict(rf_classifier, X, y, cv=num_folds)\n",
        "  mae = mean_absolute_error(y, predictions)\n",
        "\n",
        "  # Display Random Forest results\n",
        "  print(\"Random Forest Precision :\", np.mean(precision_scores))\n",
        "  print(\"Random Forest F1 Score :\", np.mean(f1_scores))\n",
        "  print(\"Random Forest Variance :\", variance)\n",
        "  print(\"Random Forest MAE :\", mae)\n",
        "  print(\"Random Forest Execution Time:\", elapsed_time)\n",
        "\n",
        "  results.append([\"Random Forest\", np.mean(precision_scores), np.mean(f1_scores), variance, mae, elapsed_time])"
      ],
      "metadata": {
        "id": "8ioZs9wkg74n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a1518e-5ff3-4ee5-9b83-9d0659c49955"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Precision : 0.9460547155556993\n",
            "Random Forest F1 Score : 0.8910964816398075\n",
            "Random Forest Variance : 0.025444219779817073\n",
            "Random Forest MAE : 0.007293098762792194\n",
            "Random Forest Execution Time: 1023.1033320426941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Save the results lists to a file\n",
        "  with open(results_file_name, 'wb') as file:\n",
        "      results_dict = {\n",
        "          'results': results,\n",
        "      }\n",
        "      pickle.dump(results_dict, file)\n"
      ],
      "metadata": {
        "id": "S1gSA8F3Gjmq"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the results from the file\n",
        "with open(results_file_name, 'rb') as file:\n",
        "    loaded_results = pickle.load(file)\n",
        "\n",
        "# Access the loaded results lists\n",
        "results = loaded_results['results']\n"
      ],
      "metadata": {
        "id": "o8NiiZpeIrJB"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results in tabular format\n",
        "headers = [\"Algorithm\", \"Precision\", \"F1 Score\", \"Variance\", \"MAE\", \"Execution Time\"]\n",
        "\n",
        "print(tabulate(results, headers, tablefmt=\"pretty\"))"
      ],
      "metadata": {
        "id": "4JqjfKOvhDZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894d599d-308a-41c6-c854-f1af7e66ad7c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+---------------------+------------------------+----------------------+--------------------+\n",
            "|   Algorithm   |     Precision      |      F1 Score       |        Variance        |         MAE          |   Execution Time   |\n",
            "+---------------+--------------------+---------------------+------------------------+----------------------+--------------------+\n",
            "|   ZeroRule    |        0.0         |         0.0         |          0.0           | 0.03279891691167001  | 5.6921117305755615 |\n",
            "|    OneRule    | 0.0333212537210722 | 0.03162443842440634 | 4.3234639380297525e-06 | 0.06329867442460932  | 5.965609788894653  |\n",
            "|  Naive Bayes  | 0.2786100231779066 | 0.4317346957207556  |  0.001716265973914469  | 0.08639872514045455  | 14.252134561538696 |\n",
            "| Random Forest | 0.9460547155556993 | 0.8910964816398075  |  0.025444219779817073  | 0.007293098762792194 | 1023.1033320426941 |\n",
            "+---------------+--------------------+---------------------+------------------------+----------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts_ISCXIDS2012 = ISCXIDS2012_df['Tag'].value_counts()\n",
        "\n",
        "# Display the counts with labels for ISCXIDS2012\n",
        "print(\"Label counts for ISCXIDS2012:\")\n",
        "print(label_counts_ISCXIDS2012)\n",
        "\n",
        "# Assuming 'Tag' is the name of the column containing your labels in df\n",
        "label_counts_df = df['Tag'].value_counts()\n",
        "\n",
        "# Display the counts with labels for df\n",
        "print(\"\\nLabel counts for df:\")\n",
        "print(label_counts_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVxALhkY4VYG",
        "outputId": "fc9e05c5-5c48-429e-d8eb-31bd50f375a0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label counts for ISCXIDS2012:\n",
            "0.0    1569542\n",
            "1.0      53225\n",
            "Name: Tag, dtype: int64\n",
            "\n",
            "Label counts for df:\n",
            "Normal    1687923\n",
            "Attack      58707\n",
            "Name: Tag, dtype: int64\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}