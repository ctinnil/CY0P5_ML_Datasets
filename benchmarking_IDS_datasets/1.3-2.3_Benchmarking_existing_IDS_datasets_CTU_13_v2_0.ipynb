{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9GPqNbjo6r2"
      },
      "source": [
        "# Intrusion Detection System (IDS) Public Datasets Benchmarking\n",
        "\n",
        "In cybersecurity, the design, development, and implementation of effective Intrusion Detection Systems (IDS) are important for safeguarding IT&C infrastructures from unauthorized access, data breaches, and various forms of malicious activities. The selection of an appropriate ML/DL algorithm plays a essential role in ensuring the security and integrity of protected systems.\n",
        "\n",
        "But before we can dive in the development of a new-edge algorithm, we shoud have the appropriate data, that needs to be studied and analysed in order to undestant the reality and challenges of our ML problem. In accordance with this paradigm, we chosed to study the early created datasets designed for IDS systems in order to derive leasons learn for feature dataset development.\n",
        "\n",
        "This experiment aims to comprehensively evaluate the performance of different ML and DL algorithms on a variety of datasets, encompassing a wide range of network traffic scenarios. The datasets used for this analysis include well-known benchmark datasets such as KDD, NSL-KDD, CTU-13, ISCXIDS2012, CIC-IDS2017, CSE-CIC-IDS2018, CIDDS-001/CIDDS-002, and Kyoto 2006+. Each dataset represents a distinct set of challenges and characteristics, making this evaluation both diverse and insightful.\n",
        "\n",
        "The experiment is divided into three main phases:\n",
        "\n",
        "1. **Data Acquisition and Preprocessing**:\n",
        " - In this phase, we acquire the selected datasets from reputable sources, ensuring the integrity and accuracy of the data.\n",
        " - Data preprocessing tasks include handling missing values, selecting the most relevant features using feature selection techniques, normalizing the data, and, if necessary, performing feature engineering to enhance the dataset's suitability for machine learning.\n",
        "\n",
        "2. **Algorithm Evaluation**:\n",
        " - We evaluate the performance of a range of ML/DL algorithms on each dataset. The chosen algorithms include baseline methods like ZeroRule and OneRule, traditional machine learning approaches like Naive Bayes and Random Forest, as well as some of the most used anomaly detection deep learning algorithms.\n",
        " - Cross-validation is applied to ensure the robustness of our results. Performance metrics such as precision, variance, and Mean Absolute Error (MAE) are calculated for each algorithm and dataset.\n",
        "\n",
        "3. **Results and Insights**:\n",
        " - The results of this evaluation provide valuable insights into the strengths and weaknesses of different IDS algorithms under various conditions.\n",
        " - We analyze the performance of algorithms on both the original datasets and balanced datasets to address the challenge of class imbalance in intrusion detection.\n",
        " - Observations and additional details regarding the algorithms' performance are documented, providing a comprehensive overview of their behavior.\n",
        "\n",
        "By conducting this experiment, we aim to contribute to the understanding of cyber domain dataset generation. The findings will assist in making informed decisions when developing a cybersecurity AI application, by deriving necesary steps and procedures in selecting the appropriate learning data.\n",
        "\n",
        "The following sections of this Jupyter notebook will provide a detailed walkthrough of the experiment, including code snippets, visualizations, and discussions of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtMV8ZjUwala",
        "outputId": "641b9220-c235-486a-8f13-ecbdc1d540c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "miTHccsrPV8K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "from google.colab import files\n",
        "\n",
        "# Suppress all warning messages\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Check if the Kaggle API credentials file already exists\n",
        "kaggle_credentials_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
        "\n",
        "if not os.path.exists(kaggle_credentials_path):\n",
        "\n",
        "    if not os.path.exists(os.path.join(\"/content/drive/MyDrive/.kaggle/\", \"kaggle.json\")):\n",
        "\n",
        "      # Upload your Kaggle API credentials file (kaggle.json)\n",
        "      files.upload()\n",
        "\n",
        "      !mv kaggle.json \"/content/drive/MyDrive/.kaggle/\"\n",
        "      !chmod 600 \"/content/drive/MyDrive/.kaggle/kaggle.json\"\n",
        "\n",
        "    # Move the Kaggle API Credentials File\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp '/content/drive/MyDrive/.kaggle/kaggle.json' ~/.kaggle/\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"Kaggle API credentials file already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ2mwpZghvQv",
        "outputId": "4dbf73da-2948-4e4a-be9c-63badae24afc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-277be1330e1a>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU device name: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.test.is_gpu_available())\n",
        "print(\"GPU device name:\", tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahPNolp1hx9y",
        "outputId": "c4011b4a-444e-48fb-a464-583db319a87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+--------------------------------+\n",
            "|  Characteristic  |             Value              |\n",
            "+------------------+--------------------------------+\n",
            "|     CPU Type     | Intel(R) Xeon(R) CPU @ 2.20GHz |\n",
            "| CPU Architecture |             x86_64             |\n",
            "|    Total RAM     |            54.76 GB            |\n",
            "|  Available RAM   |            52.17 GB            |\n",
            "|     GPU Name     |            Tesla T4            |\n",
            "| GPU Total Memory |            15360 MB            |\n",
            "| GPU Used Memory  |             359 MB             |\n",
            "| GPU Free Memory  |            14742 MB            |\n",
            "+------------------+--------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from psutil import virtual_memory\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Function to get CPU information\n",
        "def get_cpu_info():\n",
        "    cpu_info = os.popen('lscpu').read()\n",
        "    return cpu_info\n",
        "\n",
        "# Function to get RAM information\n",
        "def get_ram_info():\n",
        "    ram = virtual_memory()\n",
        "    total_ram = f\"{ram.total / 1e9:.2f} GB\"\n",
        "    available_ram = f\"{ram.available / 1e9:.2f} GB\"\n",
        "    return total_ram, available_ram\n",
        "\n",
        "# Function to get GPU information\n",
        "def get_gpu_info():\n",
        "    # Execute nvidia-smi and get its output\n",
        "    gpu_info = os.popen('nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits').read().strip()\n",
        "\n",
        "    # Split the output to get individual GPU details\n",
        "    details = gpu_info.split(\", \")\n",
        "\n",
        "    # Return GPU name, total, used, and free memory\n",
        "    return details[0], f\"{details[1]} MB\", f\"{details[2]} MB\", f\"{details[3]} MB\"\n",
        "\n",
        "# Collect system information\n",
        "cpu_info = get_cpu_info()\n",
        "total_ram, available_ram = get_ram_info()\n",
        "try:\n",
        "  gpu_name, gpu_total_memory, gpu_used_memory, gpu_free_memory = get_gpu_info()\n",
        "except:\n",
        "  gpu_name, gpu_total_memory, gpu_used_memory, gpu_free_memory = 'null',0,0,0\n",
        "\n",
        "# Extract relevant CPU information\n",
        "cpu_type = \"\"\n",
        "cpu_architecture = \"\"\n",
        "\n",
        "for line in cpu_info.splitlines():\n",
        "    if \"Model name:\" in line:\n",
        "        cpu_type = line.split(\":\")[1].strip()\n",
        "    elif \"Architecture:\" in line:\n",
        "        cpu_architecture = line.split(\":\")[1].strip()\n",
        "\n",
        "# Create a table\n",
        "table = [\n",
        "    [\"CPU Type\", cpu_type],\n",
        "    [\"CPU Architecture\", cpu_architecture],\n",
        "    [\"Total RAM\", total_ram],\n",
        "    [\"Available RAM\", available_ram],\n",
        "    [\"GPU Name\", gpu_name],\n",
        "    [\"GPU Total Memory\", gpu_total_memory],\n",
        "    [\"GPU Used Memory\", gpu_used_memory],\n",
        "    [\"GPU Free Memory\", gpu_free_memory]\n",
        "]\n",
        "\n",
        "# Display the table\n",
        "print(tabulate(table, headers=[\"Characteristic\", \"Value\"], tablefmt=\"pretty\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzsb4uZasyyg"
      },
      "source": [
        "## 1. Data Acquisition and Preprocessing\n",
        "\n",
        "In this section, we focus on acquiring the above mentioned datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-rZmvktk4m"
      },
      "source": [
        "### 1.3. CTU-13 dataset\n",
        "\n",
        "The CTU-13 dataset was specifically tailored for evaluating the detection of botnet activities within network traffic data. The dataset was derived from real-world network traffic captured in a controlled laboratory environment. It consists of thirteen different scenarios, each representing a specific network attack or intrusion scenario. These scenarios cover a wide range of cyber threats, including botnet activity, Distributed Denial of Service (DDoS) attacks, and various intrusion attempts, making it indispensable for our study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIJ4uY7hK9Dk"
      },
      "source": [
        "### Download and Unzip CTU-13 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZJZ_BPiWFa3",
        "outputId": "8f490530-387d-4223-fbec-6b63afff4eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ctu13.zip to /content/drive/MyDrive/CTU13-BM\n",
            " 98% 100M/102M [00:06<00:00, 21.2MB/s] \n",
            "100% 102M/102M [00:06<00:00, 16.4MB/s]\n",
            "Download complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the dataset name\n",
        "dataset_name = \"dhoogla/ctu13\"\n",
        "\n",
        "# Specify the destination folder in your Google Drive\n",
        "destination_folder = \"/content/drive/MyDrive/CTU13-BM\"\n",
        "\n",
        "# Check if the dataset file already exists in your Google Drive\n",
        "dataset_file_path = os.path.join(destination_folder, \"ctu13.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_file_path):\n",
        "\n",
        "  # Download the dataset and save it to your Google Drive\n",
        "  !kaggle datasets download -d $dataset_name -p $destination_folder\n",
        "\n",
        "  # Unzip the downloaded dataset\n",
        "  import zipfile\n",
        "  with zipfile.ZipFile(f\"{destination_folder}/ctu13.zip\", \"r\") as zip_ref:\n",
        "      zip_ref.extractall(destination_folder)\n",
        "\n",
        "  print(\"Download complete.\")\n",
        "\n",
        "else:\n",
        "  print(\"Dataset already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MMlugG0zTNG",
        "outputId": "050c25ef-5340-4f41-e712-2e6ac13673a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 219M\n",
            "-rw------- 1 root root 9.0M Oct 10 16:43 10-Rbot-20110818.binetflow.parquet\n",
            "-rw------- 1 root root 830K Oct 10 16:43 11-Rbot-20110818-2.binetflow.parquet\n",
            "-rw------- 1 root root 2.6M Oct 10 16:43 12-NsisAy-20110819.binetflow.parquet\n",
            "-rw------- 1 root root  11M Oct 10 16:43 13-Virut-20110815-3.binetflow.parquet\n",
            "-rw------- 1 root root  18M Oct 10 16:43 1-Neris-20110810.binetflow.parquet\n",
            "-rw------- 1 root root  12M Oct 10 16:43 2-Neris-20110811.binetflow.parquet\n",
            "-rw------- 1 root root  21M Oct 10 16:43 3-Rbot-20110812.binetflow.parquet\n",
            "-rw------- 1 root root 8.0M Oct 10 16:43 4-Rbot-20110815.binetflow.parquet\n",
            "-rw------- 1 root root 1.1M Oct 10 16:43 5-Virut-20110815-2.binetflow.parquet\n",
            "-rw------- 1 root root 4.2M Oct 10 16:43 6-Menti-20110816.binetflow.parquet\n",
            "-rw------- 1 root root 993K Oct 10 16:43 7-Sogou-20110816-2.binetflow.parquet\n",
            "-rw------- 1 root root  17M Oct 10 16:43 8-Murlo-20110816-3.binetflow.parquet\n",
            "-rw------- 1 root root  15M Oct 10 16:43 9-Neris-20110817.binetflow.parquet\n",
            "-rw------- 1 root root 102M Aug 12  2022 ctu13.zip\n"
          ]
        }
      ],
      "source": [
        "!ls -ahl '/content/drive/MyDrive/CTU13-BM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pewkvBHgL7ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Specify the destination folder in your Google Drive\n",
        "destination_folder = \"/content/drive/MyDrive/CTU13-BM\"\n",
        "\n",
        "# List to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Walk through the directory and find .parquet files\n",
        "for root, dirs, files in os.walk(destination_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.parquet'):\n",
        "            filepath = os.path.join(root, file)\n",
        "            dfs.append(pd.read_parquet(filepath))\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "df = pd.concat(dfs, copy=False, ignore_index=True, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWTTwOftQFCM",
        "outputId": "dad94b8c-3b19-45d9-a7f6-bf42c80e7a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10598771 entries, 0 to 10598770\n",
            "Data columns (total 11 columns):\n",
            " #   Column     Dtype  \n",
            "---  ------     -----  \n",
            " 0   dur        float32\n",
            " 1   proto      object \n",
            " 2   dir        object \n",
            " 3   state      object \n",
            " 4   stos       float32\n",
            " 5   dtos       float32\n",
            " 6   tot_pkts   int32  \n",
            " 7   tot_bytes  int64  \n",
            " 8   src_bytes  int64  \n",
            " 9   label      object \n",
            " 10  Family     object \n",
            "dtypes: float32(3), int32(1), int64(2), object(5)\n",
            "memory usage: 727.8+ MB\n"
          ]
        }
      ],
      "source": [
        "# Information about the starting CTU-13 DataFrame\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8wX454k6sBI1",
        "outputId": "a5f742cc-31cc-4758-dfb0-d481c121500b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14dc6dc9-6629-45df-8819-6d92d14e430c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dur</th>\n",
              "      <th>stos</th>\n",
              "      <th>dtos</th>\n",
              "      <th>tot_pkts</th>\n",
              "      <th>tot_bytes</th>\n",
              "      <th>src_bytes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.059877e+07</td>\n",
              "      <td>1.051298e+07</td>\n",
              "      <td>9.690363e+06</td>\n",
              "      <td>1.059877e+07</td>\n",
              "      <td>1.059877e+07</td>\n",
              "      <td>1.059877e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.401320e+02</td>\n",
              "      <td>8.291562e-03</td>\n",
              "      <td>7.676699e-04</td>\n",
              "      <td>7.589311e+01</td>\n",
              "      <td>6.044535e+04</td>\n",
              "      <td>1.202909e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.077755e+03</td>\n",
              "      <td>1.006990e+00</td>\n",
              "      <td>4.455093e-02</td>\n",
              "      <td>7.613475e+03</td>\n",
              "      <td>5.468097e+06</td>\n",
              "      <td>2.289821e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>6.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.451000e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.660000e+02</td>\n",
              "      <td>8.100000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.166350e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>5.500000e+02</td>\n",
              "      <td>2.220000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.339011e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.100000e+01</td>\n",
              "      <td>2.179000e+03</td>\n",
              "      <td>9.520000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.657061e+03</td>\n",
              "      <td>1.920000e+02</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.658064e+07</td>\n",
              "      <td>4.376239e+09</td>\n",
              "      <td>3.423408e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14dc6dc9-6629-45df-8819-6d92d14e430c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14dc6dc9-6629-45df-8819-6d92d14e430c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14dc6dc9-6629-45df-8819-6d92d14e430c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb012c61-bddb-4221-a26c-7a57f6e73cc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb012c61-bddb-4221-a26c-7a57f6e73cc1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb012c61-bddb-4221-a26c-7a57f6e73cc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                dur          stos          dtos      tot_pkts     tot_bytes  \\\n",
              "count  1.059877e+07  1.051298e+07  9.690363e+06  1.059877e+07  1.059877e+07   \n",
              "mean   5.401320e+02  8.291562e-03  7.676699e-04  7.589311e+01  6.044535e+04   \n",
              "std    1.077755e+03  1.006990e+00  4.455093e-02  7.613475e+03  5.468097e+06   \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  6.000000e+01   \n",
              "25%    5.451000e-03  0.000000e+00  0.000000e+00  2.000000e+00  2.660000e+02   \n",
              "50%    7.166350e-01  0.000000e+00  0.000000e+00  4.000000e+00  5.500000e+02   \n",
              "75%    1.339011e+02  0.000000e+00  0.000000e+00  1.100000e+01  2.179000e+03   \n",
              "max    3.657061e+03  1.920000e+02  3.000000e+00  1.658064e+07  4.376239e+09   \n",
              "\n",
              "          src_bytes  \n",
              "count  1.059877e+07  \n",
              "mean   1.202909e+04  \n",
              "std    2.289821e+06  \n",
              "min    0.000000e+00  \n",
              "25%    8.100000e+01  \n",
              "50%    2.220000e+02  \n",
              "75%    9.520000e+02  \n",
              "max    3.423408e+09  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Some basic statistical details like percentile, mean, std, etc. of the starting CTU-13 DataFrame\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqxSP98_I9pl",
        "outputId": "2b404f69-6ddf-4d84-8584-b31b3f066f2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10598771, 11),\n",
              " Index(['dur', 'proto', 'dir', 'state', 'stos', 'dtos', 'tot_pkts', 'tot_bytes',\n",
              "        'src_bytes', 'label', 'Family'],\n",
              "       dtype='object'))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape, df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvj84YsGLpvv",
        "outputId": "7ca0883c-bcf1-431e-ce58-512bb60725d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10598771, 10)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dropping  'Family' as it is an irrelevant feature\n",
        "\n",
        "df = df.drop(columns=['Family'])\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ihheceqKT8V"
      },
      "source": [
        "### Preprocessing of the CTU-13 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFfhQvIk7jMn",
        "outputId": "c3fb73aa-6e9f-4be5-aaa6-87dd87937358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dur               0\n",
            "proto             0\n",
            "dir               0\n",
            "state            76\n",
            "stos          85794\n",
            "dtos         908408\n",
            "tot_pkts          0\n",
            "tot_bytes         0\n",
            "src_bytes         0\n",
            "label             0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check if the Dataset was not preprocess do:\n",
        "  # 1 # Handling Missing Values\n",
        "  # 2 # Encode Categorical Features and Label\n",
        "  # 3 # Normalization (Min-Max Scaling)\n",
        "  # 4 # Removing duplicate records\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df_encoded_file_path = os.path.join(destination_folder, \"ctu13_scaled.csv\")\n",
        "if not os.path.exists(df_encoded_file_path):\n",
        "\n",
        "  # Step 1: Handling Missing Values\n",
        "\n",
        "  # Check for missing values, NAN\n",
        "  check_nan = df.isna().sum(axis=0)\n",
        "  print(check_nan)\n",
        "\n",
        "  # Impute missing values with the most frequent value for categorical columns and mean for numerical columns\n",
        "  if (df.isna().sum().sum() !=0):\n",
        "    imputer = SimpleImputer(strategy='most_frequent', missing_values=pd.NA)\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = imputer.fit_transform(df[[col]])\n",
        "        else:\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "# If you want to simply remove the nan rows you could do the following\n",
        "\n",
        "# Print the shape (number of rows and columns) of the CTU-13 DataFrame 'df' before any modifications\n",
        "#print(df.shape)\n",
        "\n",
        "# Remove rows with missing values (NaN) from the DataFrame 'df'\n",
        "#df = df.dropna()\n",
        "\n",
        "# Reprint the shape\n",
        "#print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0AJQXkZNPlK",
        "outputId": "d67000a8-eab9-4b8b-c366-92f8b6c83e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dur          0\n",
              "proto        0\n",
              "dir          0\n",
              "state        0\n",
              "stos         0\n",
              "dtos         0\n",
              "tot_pkts     0\n",
              "tot_bytes    0\n",
              "src_bytes    0\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check again for missing values, NAN\n",
        "df.isna().sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Jo-kwZVfMuOY"
      },
      "outputs": [],
      "source": [
        "  # 2 # Encode Categorical Features and Label\n",
        "\n",
        "# Rransforming specific columns in the CTU-13 DataFrame to categorical data types, encoding them as integer codes, and then reducing their memory usage by changing the data type to 32-bit integers.\n",
        "# This can be useful for reducing memory consumption when dealing with large datasets with categorical features.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df['proto'] = df['proto'].astype('category').cat.codes\n",
        "df['proto'] = df['proto'].astype(np.int32)\n",
        "df['dir'] = df['dir'].astype('category').cat.codes\n",
        "df['dir'] = df['dir'].astype(np.int32)\n",
        "df['state'] = df['state'].astype('category').cat.codes\n",
        "df['state'] = df['state'].astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwFkk2TtOzwY",
        "outputId": "ecaaccd1-9c2d-4024-e0fb-6762a145123b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flow=Background-UDP-Established           4151793\n",
            "flow=Background-TCP-Established           2054183\n",
            "flow=To-Background-UDP-CVUT-DNS-Server    1659760\n",
            "flow=Background-Established-cmpgw-CVUT     855498\n",
            "flow=Background-UDP-Attempt                492881\n",
            "flow=Background-TCP-Attempt                355420\n",
            "flow=Background                            178154\n",
            "flow=To-Background-CVUT-Proxy              149570\n",
            "flow=Background-Attempt-cmpgw-CVUT          54956\n",
            "flow=To-Background-CVUT-WebServer           45227\n",
            "Name: label, dtype: int64\n",
            "0.0    10336198\n",
            "1.0      262573\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the top 10 most frequent values and their counts in the 'label' column of CTU-13\n",
        "print(df.label.value_counts().head(10))\n",
        "\n",
        "# Change the data type of the 'label' column to 'object' (string)\n",
        "df['label'] = df['label'].astype(dtype='object')\n",
        "\n",
        "# Check if the 'label' column starts with the string 'flow=From-Botnet', and assign a Boolean value accordingly\n",
        "df['label'] = df['label'].str.startswith('flow=From-Botnet', na=False)\n",
        "\n",
        "# Change the data type of the 'label' column to 'float32'\n",
        "df['label'] = df['label'].astype(dtype='float32', copy=False)\n",
        "\n",
        "# Display again the top 10 most frequent values and their counts in the 'label' column of CTU-13 after modifications\n",
        "print(df.label.value_counts().head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lwUFxJ4x-Lf5"
      },
      "outputs": [],
      "source": [
        "  # 3 # Normalization (Min-Max Scaling)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if the Dataset was not preprocessed:\n",
        "if not os.path.exists(df_encoded_file_path):\n",
        "    min_max_scaler = MinMaxScaler().fit(df)  # Fit the scaler to the data in 'df'\n",
        "    df_scaled = pd.DataFrame(data=min_max_scaler.transform(df), columns=df.columns)  # Create a new DataFrame with scaled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs1UOtdmOop3",
        "outputId": "8e435708-196d-405b-9f7e-bb76062f89db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10598771, 10)\n",
            "(9404048, 10)\n",
            "(10598771, 10)\n",
            "(9404048, 10)\n"
          ]
        }
      ],
      "source": [
        "  # 4 # Removing duplicate records\n",
        "\n",
        "# Print the shape of the DataFrame 'df' after removing rows with missing values\n",
        "print(df.shape)\n",
        "\n",
        "# Remove duplicate rows from the DataFrame 'df' while resetting the index\n",
        "df = df.drop_duplicates()\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Print the shape of the DataFrame 'df' after removing duplicates and resetting the index\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "# Print the shape of the DataFrame 'df_scaled' after removing rows with missing values\n",
        "print(df_scaled.shape)\n",
        "\n",
        "# Remove duplicate rows from the DataFrame 'df_scaled' while resetting the index\n",
        "df_scaled = df_scaled.drop_duplicates()\n",
        "df_scaled.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Print the shape of the DataFrame 'df_scaled' after removing duplicates and resetting the index\n",
        "print(df_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-gl7hTNalVk",
        "outputId": "7ae52eb1-067d-4197-e1fa-f017a30b1e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variable    Type         Data/Info\n",
            "----------------------------------\n",
            "df          DataFrame                  dur  proto <...>404048 rows x 10 columns]\n",
            "df_scaled   DataFrame                  dur     pro<...>404048 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print out the DataFrames loaded in the memory\n",
        "%whos DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FiaCpDy9gtdc"
      },
      "outputs": [],
      "source": [
        "# Save the resulting dataframes\n",
        "\n",
        "df_file_path = '/content/drive/MyDrive/CTU13-BM/ctu13.csv'\n",
        "df_encoded_file_path = '/content/drive/MyDrive/CTU13-BM/ctu13_scaled.csv'\n",
        "\n",
        "# Check if the Dataset is saved:\n",
        "if not os.path.exists(df_file_path):\n",
        "  # Convert your Pandas DataFrame to a CSV file\n",
        "  df.to_csv(df_file_path, index=False)\n",
        "if not os.path.exists(df_encoded_file_path):\n",
        "  # Convert your Pandas DataFrame to a CSV file\n",
        "  df_scaled.to_csv(df_encoded_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGr89__ALu4n"
      },
      "source": [
        "## 2. Algorithm Evaluation\n",
        "\n",
        "In this section, we assess the performance of various machine learning algorithms on the upper mentioned datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lClNdKunMbaA"
      },
      "source": [
        "### 2.3. CTU-13 dataset evaluation with baseline and traditional ML algorithms\n",
        "\n",
        "In this section, we evaluate the performance of various machine learning algorithms on the CTU-13 botnet dataset. We assess the precision and F1 scores, essential indicators of classification accuracy, for a range of algorithms, including fundamental classifiers like Zero Rule and One Rule, statistical approaches like Naive Bayes, and more advanced models such as Random Forest.\n",
        "\n",
        "Given the CTU-13 dataset's unique characteristics, which include a limited number of features (namely 'due,' 'proto,' 'dir,' 'state,' 'stos,' 'dtos,' 'tot_pkts,' 'tot_bytes,' 'src_bytes,' and 'label'), our evaluation focuses on understanding the effectiveness of these algorithms in detecting and classifying network traffic patterns associated with botnet activities.\n",
        "\n",
        "To ensure a robust assessment, we employ a 10-fold cross-validation methodology, testing the algorithms on all the features from the dataset. These results offer valuable insights into the optimal dataset generation strategy, aiding in the selection of the most effective feature extraction methods for cybersecurity specific dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7DpcMKATGQhV"
      },
      "outputs": [],
      "source": [
        "# Skip selection of best features due to low count of attributes\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df_scaled.drop('label', axis=1)  # Exclude the label column\n",
        "y = df_scaled['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MPMCiS92fwaH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, mean_absolute_error, f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the number of desired folds for Cross-Validation (e.g., 10)\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize performance metrics lists for 9 features due to limited attributes count\n",
        "results_9_features = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6evNOm1gG1C",
        "outputId": "93a18b91-3ff7-4631-aa05-33da40decef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ZeroRule Precision (9 features): 0.0\n",
            "ZeroRule F1 Score (9 features): 0.0\n",
            "ZeroRule Variance (9 features): 0.0\n",
            "ZeroRule MAE (9 features): 0.024866100215566744\n",
            "ZeroRule Execution Time: 30.797607898712158\n"
          ]
        }
      ],
      "source": [
        "# Define a file name for saving the results\n",
        "results_file_name = os.path.join(destination_folder, \"ctu13_results.pkl\")\n",
        "\n",
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define ZeroRule classifier\n",
        "  zero_rule = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "  # Evaluate ZeroRule classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores_9 = cross_val_score(zero_rule, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores_9 = cross_val_score(zero_rule, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time_9 = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance_9 = np.var(precision_scores_9)\n",
        "\n",
        "  predictions_9 = cross_val_predict(zero_rule, X, y, cv=num_folds)\n",
        "  mae_9 = mean_absolute_error(y, predictions_9)\n",
        "\n",
        "  # Display ZeroRule results for 9 features\n",
        "  print(\"ZeroRule Precision (9 features):\", np.mean(precision_scores_9))\n",
        "  print(\"ZeroRule F1 Score (9 features):\", np.mean(f1_scores_9))\n",
        "  print(\"ZeroRule Variance (9 features):\", variance_9)\n",
        "  print(\"ZeroRule MAE (9 features):\", mae_9)\n",
        "  print(\"ZeroRule Execution Time:\", elapsed_time_9)\n",
        "\n",
        "  results_9_features.append([\"ZeroRule\", np.mean(precision_scores_9), np.mean(f1_scores_9), variance_9, mae_9, elapsed_time_9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36wkD9GMgyzS",
        "outputId": "411536db-9649-43e6-dd96-1f84f6a4684a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OneRule Precision (9 features): 0.024784734503328354\n",
            "OneRule F1 Score (9 features): 0.02493287194553043\n",
            "OneRule Variance (9 features): 8.980152971872171e-07\n",
            "OneRule MAE (9 features): 0.04843010159029388\n",
            "OneRule Execution Time: 31.0071804523468\n"
          ]
        }
      ],
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define OneRule classifier\n",
        "  one_rule = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "  # Evaluate OneRule classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores_9 = cross_val_score(one_rule, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores_9 = cross_val_score(one_rule, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time_9 = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance_9 = np.var(precision_scores_9)\n",
        "\n",
        "  predictions_9 = cross_val_predict(one_rule, X, y, cv=num_folds)\n",
        "  mae_9 = mean_absolute_error(y, predictions_9)\n",
        "\n",
        "  # Display OneRule results for 9 features\n",
        "  print(\"OneRule Precision (9 features):\", np.mean(precision_scores_9))\n",
        "  print(\"OneRule F1 Score (9 features):\", np.mean(f1_scores_9))\n",
        "  print(\"OneRule Variance (9 features):\", variance_9)\n",
        "  print(\"OneRule MAE (9 features):\", mae_9)\n",
        "  print(\"OneRule Execution Time:\", elapsed_time_9)\n",
        "\n",
        "  results_9_features.append([\"OneRule\", np.mean(precision_scores_9), np.mean(f1_scores_9), variance_9, mae_9, elapsed_time_9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M8M6iicg36h",
        "outputId": "148797a1-6dcc-4f95-d852-25375382ba1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Precision (9 features): 0.02939298880167533\n",
            "Naive Bayes F1 Score (9 features): 0.0570083052333196\n",
            "Naive Bayes Variance (9 features): 2.0994859580674664e-05\n",
            "Naive Bayes MAE (9 features): 0.7805218561198326\n",
            "Naive Bayes Execution Time: 68.04527616500854\n"
          ]
        }
      ],
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Define Naive Bayes classifier\n",
        "  naive_bayes = GaussianNB()\n",
        "\n",
        "  # Evaluate Naive Bayes classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores_9 = cross_val_score(naive_bayes, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores_9 = cross_val_score(naive_bayes, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time_9 = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance_9 = np.var(precision_scores_9)\n",
        "\n",
        "  predictions_9 = cross_val_predict(naive_bayes, X, y, cv=num_folds)\n",
        "  mae_9 = mean_absolute_error(y, predictions_9)\n",
        "\n",
        "  # Display Naive Bayes results for 9 features\n",
        "  print(\"Naive Bayes Precision (9 features):\", np.mean(precision_scores_9))\n",
        "  print(\"Naive Bayes F1 Score (9 features):\", np.mean(f1_scores_9))\n",
        "  print(\"Naive Bayes Variance (9 features):\", variance_9)\n",
        "  print(\"Naive Bayes MAE (9 features):\", mae_9)\n",
        "  print(\"Naive Bayes Execution Time:\", elapsed_time_9)\n",
        "\n",
        "  results_9_features.append([\"Naive Bayes\", np.mean(precision_scores_9), np.mean(f1_scores_9), variance_9, mae_9, elapsed_time_9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ioZs9wkg74n",
        "outputId": "9142eb41-3c5e-45e3-81e8-46b7b6b926e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Precision (9 features): 0.6757534659433394\n",
            "Random Forest F1 Score (9 features): 0.039739922209714736\n",
            "Random Forest Variance (9 features): 0.18238869891010404\n",
            "Random Forest MAE (9 features): 0.024287838598867212\n",
            "Random Forest Execution Time: 4184.681151866913\n"
          ]
        }
      ],
      "source": [
        "# Check for results before rerunning the code snippet\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Create a Random Forest classifier with optimized parameters\n",
        "  rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)  # Adjust parameters for optimization\n",
        "\n",
        "  # Evaluate Random Forest classifier\n",
        "  start_time = time.time()  # Start measuring execution time\n",
        "  precision_scores_9 = cross_val_score(rf_classifier, X, y, cv=num_folds, scoring='precision')\n",
        "  f1_scores_9 = cross_val_score(rf_classifier, X, y, cv=num_folds, scoring='f1')\n",
        "  elapsed_time_9 = time.time() - start_time  # Calculate execution time\n",
        "\n",
        "  variance_9 = np.var(precision_scores_9)\n",
        "\n",
        "  predictions_9 = cross_val_predict(rf_classifier, X, y, cv=num_folds)\n",
        "  mae_9 = mean_absolute_error(y, predictions_9)\n",
        "\n",
        "  # Display Random Forest results for 9 features\n",
        "  print(\"Random Forest Precision (9 features):\", np.mean(precision_scores_9))\n",
        "  print(\"Random Forest F1 Score (9 features):\", np.mean(f1_scores_9))\n",
        "  print(\"Random Forest Variance (9 features):\", variance_9)\n",
        "  print(\"Random Forest MAE (9 features):\", mae_9)\n",
        "  print(\"Random Forest Execution Time:\", elapsed_time_9)\n",
        "\n",
        "  results_9_features.append([\"Random Forest\", np.mean(precision_scores_9), np.mean(f1_scores_9), variance_9, mae_9, elapsed_time_9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S1gSA8F3Gjmq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "if not os.path.exists(results_file_name):\n",
        "\n",
        "  # Save the results lists to a file\n",
        "  with open(results_file_name, 'wb') as file:\n",
        "      results_dict = {\n",
        "          'results_9_features': results_9_features,\n",
        "      }\n",
        "      pickle.dump(results_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o8NiiZpeIrJB"
      },
      "outputs": [],
      "source": [
        "# Load the results from the file\n",
        "with open(results_file_name, 'rb') as file:\n",
        "    loaded_results = pickle.load(file)\n",
        "\n",
        "# Access the loaded results lists\n",
        "results_9_features = loaded_results['results_9_features']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JqjfKOvhDZx",
        "outputId": "63e1fb85-64d4-4c69-d586-d69326bbde07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------------------+----------------------+------------------------+----------------------+--------------------+\n",
            "|   Algorithm   |      Precision       |       F1 Score       |        Variance        |         MAE          |   Execution Time   |\n",
            "+---------------+----------------------+----------------------+------------------------+----------------------+--------------------+\n",
            "|   ZeroRule    |         0.0          |         0.0          |          0.0           | 0.024866100215566744 | 30.797607898712158 |\n",
            "|    OneRule    | 0.024784734503328354 | 0.02493287194553043  | 8.980152971872171e-07  | 0.04843010159029388  |  31.0071804523468  |\n",
            "|  Naive Bayes  | 0.02939298880167533  |  0.0570083052333196  | 2.0994859580674664e-05 |  0.7805218561198326  | 68.04527616500854  |\n",
            "| Random Forest |  0.6757534659433394  | 0.039739922209714736 |  0.18238869891010404   | 0.024287838598867212 | 4184.681151866913  |\n",
            "+---------------+----------------------+----------------------+------------------------+----------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print the results in tabular format\n",
        "headers_9 = [\"Algorithm\", \"Precision\", \"F1 Score\", \"Variance\", \"MAE\", \"Execution Time\"]\n",
        "\n",
        "print(tabulate(results_9_features, headers_9, tablefmt=\"pretty\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
